# Reading 2: Prompt Engineering Overview
# 提示工程概述

> **Week 1 Reading #2**
> **主题**: 提示工程的基本原则、核心概念和最佳实践
> **预计阅读时间**: 45-60 分钟

---

## 📚 导读

提示工程（Prompt Engineering）是与 LLM 有效沟通的关键技能。本文将系统介绍：

1. **什么是提示工程** - 定义和重要性
2. **核心原则** - 设计优秀提示词的基本准则
3. **常见模式** - 实用的提示词模板和技巧
4. **最佳实践** - 行业标准和经验总结

---

## 🎯 学习目标

阅读完本文后，你应该能够：

- ✅ 理解提示工程的定义和价值
- ✅ 掌握设计优秀提示词的 5 大原则
- ✅ 应用 6 种常见的提示模式
- ✅ 避免常见的提示设计错误
- ✅ 能够系统性地优化提示效果

---

## 第一部分：什么是提示工程？

### 定义

**提示工程（Prompt Engineering）** 是设计和优化提示词（prompts），以引导 LLM 生成期望输出的技术和艺术。

**关键要素**:
```
提示词 = 指令 + 上下文 + 示例 + 约束
```

### 为什么重要？

#### 1. LLM 是概率模型

同一请求可能产生不同输出：

**示例**:
```
提示词: "写一个关于猫的故事"

可能输出 1:
"从前有一只名叫 Fluffy 的猫，它喜欢在屋顶上看月亮..."

可能输出 2:
"猫咪是人类最好的朋友之一。它们的祖先可以追溯到..."

可能输出 3:
"三毛流浪记是一部经典的中国漫画..."
（模型理解错了，以为"猫"是名字）
```

**提示工程的作用**: 通过清晰的上下文减少不确定性

#### 2. 上下文敏感

**❌ 糟糕的提示**:
```
"修复这个bug"
```

**问题**: LLM 不知道
- 什么 bug？
- 在哪个文件？
- 期望的行为是什么？

**✅ 优秀的提示**:
```
请修复以下 bug：

【文件】src/utils/auth.py
【问题描述】用户登录后，session 没有正确保存
【错误日志】TypeError: Object of type NoneType is not JSON serializable
【期望行为】登录成功后，session 应包含用户 ID 和 username
【相关代码】
```python
def login(username, password):
    user = authenticate(username, password)
    if user:
        session['user_id'] = user.id  # 这里可能有问题
        session['username'] = user.username
```

请：
1. 分析问题根因
2. 提供修复代码
3. 说明为什么会出现这个问题
```

#### 3. 能力边界引导

LLM 需要合适的引导才能发挥最大潜力：

**❌ 未充分利用**:
```
"帮我写代码"
```

**✅ 充分利用**:
```
你是一位有 10 年经验的资深 Python 开发者。
请使用 Flask 和 SQLAlchemy 实现一个 RESTful API，包括：
- 用户注册和登录
- JWT 认证
- CRUD 操作
- 输入验证
- 错误处理

要求：
- 遵循 PEP 8 规范
- 包含类型注解
- 添加文档字符串
- 编写单元测试（覆盖率 > 80%）
```

---

## 第二部分：核心原则

### 原则 1: 清晰性（Clarity）

**定义**: 提示词应该明确、具体、无歧义。

**对比示例**:

#### ❌ 模糊的提示
```
"优化这个函数"
```

**问题**:
- 优化什么？速度？内存？可读性？
- 当前的瓶颈是什么？
- 有什么约束条件？

#### ✅ 清晰的提示
```
请优化以下函数以提高执行速度：

【当前实现】
```python
def find_duplicates(items):
    duplicates = []
    for i in range(len(items)):
        for j in range(i + 1, len(items)):
            if items[i] == items[j] and items[i] not in duplicates:
                duplicates.append(items[i])
    return duplicates
```

【性能问题】
当前时间复杂度是 O(n²)，在处理 10,000 个项目时需要 5 秒

【要求】
- 目标：时间复杂度降低到 O(n) 或 O(n log n)
- 保持相同的输出格式
- 返回每个重复元素的第一次出现位置
- 允许使用标准库

【输入规模】
通常处理 10K - 100K 个项目
```

### 原则 2: 上下文（Context）

**定义**: 提供足够的背景信息，让 LLM 理解任务环境。

**上下文框架**:

#### 1. 项目背景
```
【项目类型】
电商网站后端 API

【技术栈】
- 框架：FastAPI 0.104
- 数据库：PostgreSQL 15
- ORM：SQLAlchemy 2.0
- 缓存：Redis 7.0
- 认证：JWT

【当前问题】
需要实现一个购物车功能，支持：
- 添加/删除商品
- 修改数量
- 计算总价
- 持久化到数据库
```

#### 2. 现有代码上下文
```
【相关代码结构】
src/
├── models/
│   ├── user.py
│   ├── product.py
│   └── cart.py  # 需要创建
├── schemas/
│   ├── user.py
│   └── product.py
└── api/
    └── routes.py

【参考现有模式】
请参考 src/models/product.py 的模式创建 Cart 模型
```

#### 3. 业务规则
```
【业务规则】
1. 购物车最多 50 件商品
2. 同一商品数量不能超过库存
3. 未登录用户的购物车保存到 localStorage
4. 登录后自动合并购物车
5. 购物车数据保留 30 天
```

### 原则 3: 示例驱动（Example-Driven）

**定义**: 通过 few-shot learning 提供示例，引导模型理解期望。

**示例类型**:

#### 1. 输入-输出示例
```
任务：将自然语言转换为 SQL 查询

示例 1:
输入："显示所有价格大于 100 的产品"
输出：SELECT * FROM products WHERE price > 100;

示例 2:
输入："列出名字以 A 开头的客户"
输出：SELECT * FROM customers WHERE name LIKE 'A%';

示例 3:
输入："统计每个订单的商品总数"
输出：SELECT order_id, COUNT(*) as item_count
      FROM order_items
      GROUP BY order_id;

现在：
输入："显示销售量前 10 的产品"
输出：
```

#### 2. 风格示例
```
任务：重构代码以提高可读性

示例 - 重构前：
```python
def f(x):
    if x>0:
        return 1
    else:
        if x==0:
            return 0
        else:
            return -1
```

示例 - 重构后：
```python
def sign(x: float) -> int:
    """
    Return the sign of a number.

    Args:
        x: Input number

    Returns:
        1 if x > 0, 0 if x == 0, -1 if x < 0
    """
    if x > 0:
        return 1
    elif x == 0:
        return 0
    else:
        return -1
```

注意改进：
1. 添加了类型注解
2. 添加了文档字符串
3. 使用 elif 简化嵌套
4. 改进了函数命名

现在请重构以下代码：
```

#### 3. 推理链示例（ReAct 框架）

```
任务：回答技术问题

示例 1:
问题："Python 中的装饰器是什么？"

思考 1: 装饰器是 Python 的高级特性
思考 2: 它允许在不修改原函数的情况下扩展功能
思考 3: 本质上是接受函数并返回新函数的高阶函数

行动：
提供装饰器的定义、语法、示例和常见用例

观察：回答涵盖了概念、语法和实际应用

示例 2:
问题："什么是 RESTful API？"

思考 1: REST 是一种软件架构风格
思考 2: RESTful 遵循 REST 原则的 API
思考 3: 关键特性包括：无状态、统一接口、资源导向

行动：
解释 REST 原则、HTTP 方法对应关系、资源设计

观察：回答清晰解释了架构风格和实际应用

现在：
问题："什么是 Docker 容器？"
```

### 原则 4: 结构化（Structure）

**定义**: 使用清晰的结构组织提示词，提高可读性和可维护性。

**推荐结构**:

```
# [角色设定]

你是一位[角色描述]，[专业背景和经验]

---

## [任务概述]

[简要描述要完成的任务]

---

## [背景信息]

### 项目背景
[项目类型、目标、用户群体]

### 技术背景
[技术栈、架构、约束]

### 当前状态
[现有实现、问题、限制]

---

## [详细要求]

### 功能要求
1. [要求 1]
2. [要求 2]
3. [要求 3]

### 非功能要求
- 性能：[具体指标]
- 安全：[安全要求]
- 可维护性：[代码质量要求]

---

## [约束条件]

- [约束 1]
- [约束 2]
- [约束 3]

---

## [输出格式]

请按以下格式输出：

### [代码]
\`\`\`[language]
...
\`\`\`

### [解释]
...

### [测试]
...

---

## [示例]

[如果需要，提供示例]
```

### 原则 5: 迭代优化（Iteration）

**定义**: 通过多次迭代逐步改进提示效果。

**迭代流程**:

```
第 1 版：基础提示
↓ 测试
↓ 分析问题
↓

第 2 版：添加上下文
↓ 测试
↓ 分析问题
↓

第 3 版：添加示例
↓ 测试
↓ 分析问题
↓

第 4 版：添加约束
↓ 测试
↓ 最终版本
```

**示例**:

#### V1: 基础版本
```
"写一个快速排序算法"
```

**问题**:
- 没有指定语言
- 没有风格要求
- 缺少错误处理

#### V2: 添加语言和风格
```
"用 Python 写一个快速排序算法，遵循 PEP 8 规范"
```

**问题**:
- 没有处理边界情况
- 没有类型注解

#### V3: 添加详细要求
```
"用 Python 写一个快速排序算法，要求：
1. 遵循 PEP 8 规范
2. 包含类型注解
3. 处理空列表和单元素列表
4. 添加文档字符串
5. 包含测试用例"
```

**结果**: 满意的实现

---

## 第三部分：常见提示模式

### 模式 1: 角色设定（Role Playing）

**作用**: 通过设定角色，引导模型采用特定的专业视角和风格。

**示例**:

#### 技术专家角色
```
你是一位有 15 年经验的首级软件架构师，
曾在 Google 和 Meta 领导过大规模分布式系统开发。

你擅长：
- 系统架构设计
- 性能优化
- 技术决策
- 代码审查

请以专业的角度回答以下问题...
```

#### 教学角色
```
你是一位经验丰富的编程教师，
擅长用简单易懂的方式解释复杂概念。

你的教学风格：
1. 从具体例子开始
2. 逐步抽象到理论
3. 提供可视化解释
4. 给出实践练习

请解释 [主题]...
```

#### 审查者角色
```
你是一位严格的代码审查者，
关注代码质量、安全性、性能和可维护性。

审查时你会检查：
1. 是否符合 SOLID 原则
2. 是否有安全漏洞
3. 是否有性能问题
4. 是否易于测试和维护

请审查以下代码...
```

### 模式 2: 思维链（Chain-of-Thought）

**作用**: 引导模型展示推理过程，提高复杂问题的准确性。

**模板**:

```
请按以下步骤思考并回答：

## 第一步：理解问题
- 问题的核心是什么？
- 需要解决什么？
- 有什么关键信息？

## 第二步：分析可能方案
- 列出 2-3 种可能的解决方案
- 分析每种方案的优缺点

## 第三步：选择最优方案
- 说明选择理由
- 考虑约束条件

## 第四步：详细实现
- 提供具体实现步骤
- 包含代码或详细说明

## 第五步：验证结果
- 如何验证方案正确性
- 需要什么测试

---

现在请回答：[问题]
```

**示例应用**:

```
问题：如何设计一个高并发的秒杀系统？

第一步：理解问题
核心：短时间内大量用户抢购少量商品
挑战：防止超卖、保证公平、系统稳定

第二步：分析方案
方案 A: 数据库锁机制
- 优点：简单
- 缺点：性能差，数据库压力大

方案 B: Redis 缓存 + 消息队列
- 优点：高性能，异步处理
- 缺点：实现复杂

方案 C: 分布式锁 + 预扣库存
- 优点：平衡性能和一致性
- 缺点：需要处理分布式事务

第三步：选择方案 C
理由：
1. Redis 提供高性能计数
2. 消息队列保证最终一致性
3. 分布式锁防止超卖

第四步：实现步骤
1. 前置：将商品库存加载到 Redis
2. 秒杀：用户请求时，Redis 原子扣减
3. 异步：通过消息队列创建订单
4. 回滚：未支付订单释放库存

第五步：验证
- 压力测试：模拟 10万 并发
- 数据一致性：检查库存准确
- 用户体验：响应时间 < 100ms
```

### 模式 3: 自我反思（Self-Reflection）

**作用**: 引导模型检查和改进自己的输出。

**模板**:

```
请完成以下任务，并进行自我检查：

## 任务
[任务描述]

## 初稿
请提供初步答案

## 自我检查
1. 准确性检查
   - 是否有事实错误？
   - 是否有逻辑矛盾？

2. 完整性检查
   - 是否遗漏了重要方面？
   - 是否需要更多细节？

3. 清晰性检查
   - 表达是否清晰？
   - 是否需要更好的组织？

4. 改进建议
   - 哪些地方可以改进？
   - 如何优化？

## 最终版本
根据自我检查，提供改进后的最终答案
```

### 模式 4: 分步骤（Step-by-Step）

**作用**: 将复杂任务分解为可管理的步骤。

**模板**:

```
任务：[任务描述]

请按以下步骤执行：

### 第 1 步：[步骤名称]
- 具体要求：
  - [要求 1]
  - [要求 2]
- 输出：[期望输出]
- 验证：[如何验证正确性]

### 第 2 步：[步骤名称]
- 依赖：第 1 步的输出
- 具体要求：...
- 输出：...
- 验证：...

### 第 3 步：[步骤名称]
...

### 第 4 步：最终整合
- 整合前面所有步骤的结果
- 提供完整的解决方案
- 包含使用说明
```

### 模式 5: 约束条件（Constraints）

**作用**: 明确限制和边界条件。

**约束类型**:

#### 1. 技术约束
```
技术约束：
- 使用 Python 3.12+
- 仅使用标准库
- 不支持第三方依赖
- 时间复杂度不超过 O(n log n)
- 空间复杂度不超过 O(n)
```

#### 2. 代码风格约束
```
代码风格：
- 遵循 PEP 8 规范
- 函数名使用 snake_case
- 类名使用 PascalCase
- 每行不超过 88 字符
- 添加类型注解
- 文档字符串使用 Google 风格
```

#### 3. 业务约束
```
业务约束：
- 单个订单最多 50 件商品
- 折扣不能超过 50%
- 库存不能为负数
- 用户年龄必须 18+
- 支持的支付方式：信用卡、PayPal
```

#### 4. 安全约束
```
安全要求：
- 所有输入必须验证
- SQL 查询必须参数化
- 敏感数据必须加密
- API 必须认证
- 错误信息不能泄露系统信息
```

### 模式 6: 输出格式（Output Format）

**作用**: 指定期望的输出格式。

**格式类型**:

#### 1. 代码格式
```
请按以下格式输出：

## 完整代码
\`\`\`python
# 文件：[文件名]
# 作者：[作者]
# 日期：[日期]

[代码]

# 测试
\`\`\`

## 代码说明
### 功能
[功能描述]

### 复杂度分析
- 时间复杂度：O(?)
- 空间复杂度：O(?)

### 使用示例
\`\`\`python
[示例代码]
\`\`\`
```

#### 2. 文档格式
```
请按以下格式输出：

# [标题]

## 概述
[简要描述]

## 安装
\`\`\`bash
[安装命令]
\`\`\`

## 快速开始
\`\`\`python
[示例代码]
\`\`\`

## API 文档
### [函数/类 1]
[详细说明]

### [函数/类 2]
...

## 常见问题
### Q1: [问题]
A: [答案]
```

#### 3. 分析报告格式
```
请按以下格式输出：

# [分析报告标题]

## 执行摘要
[关键发现]

## 详细分析
### [类别 1]
- 发现：[具体发现]
- 影响：[影响评估]
- 建议：[改进建议]

### [类别 2]
...

## 结论
[总结性结论]

## 行动计划
1. [行动项 1]
2. [行动项 2]
3. [行动项 3]
```

---

## 第四部分：常见错误

### 错误 1: 过于简略

**❌ 示例**:
```
"修复代码"
```

**问题**: 缺少所有必要信息

**✅ 改进**:
```
请修复以下代码中的 bug：

【代码】
```python
[具体代码]
```

【问题描述】
[具体描述错误现象]

【期望行为】
[描述正确的行为]

【错误日志】
[如果有，提供错误信息]
```

### 错误 2: 矛盾的要求

**❌ 示例**:
```
"写一个简单的快速排序实现，
但需要包含所有边界情况处理、
完整的错误处理、
详细的日志记录、
性能监控、
单元测试、
集成测试、
文档字符串"
```

**问题**: "简单"和"完整"矛盾

**✅ 改进**:
```
写一个生产级的快速排序实现，包括：
- 基本的快速排序算法
- 处理空列表和单元素列表
- 类型注解和文档字符串
- 基本的错误处理
- 简单的单元测试（3-5 个测试用例）
```

### 错误 3: 缺少验证标准

**❌ 示例**:
```
"优化这个函数"
```

**问题**: 没有说明如何判断优化成功

**✅ 改进**:
```
优化以下函数：

【当前实现】
[代码]

【性能基准】
当前：处理 10K 数据需要 2 秒

【优化目标】
- 处理 10K 数据不超过 0.5 秒（4x 提升）
- 内存使用不超过 2 倍
- 保持相同的输出
- 代码可读性不能下降太多

【验证方法】
使用提供的 benchmark.py 测试性能
```

### 错误 4: 忽略边界情况

**❌ 示例**:
```
"写一个除法函数"
```

**问题**: 没有考虑除以零

**✅ 改进**:
```
写一个安全的除法函数，要求：
1. 处理除以零的情况（返回 None 或抛出异常）
2. 处理非数字输入（TypeError）
3. 处理浮点数精度问题
4. 包含类型注解
5. 添加文档字符串
6. 提供测试用例（包括边界情况）
```

### 错误 5: 格式混乱

**❌ 示例**:
```
请写一个函数计算平均值然后排序然后输出到文件还要处理错误并且要有日志还有单元测试
```

**问题**: 一段文字，难以阅读

**✅ 改进**:
```
请实现一个数据批处理流程，包括以下功能：

### 功能要求
1. 计算数据平均值
2. 对数据排序
3. 将结果输出到文件

### 错误处理
- 文件不存在：创建新文件
- 权限问题：抛出明确异常
- 数据为空：记录警告

### 日志记录
- 记录每个步骤的开始和结束
- 记录错误和警告
- 日志级别：INFO

### 测试
- 单元测试覆盖所有功能
- 包含边界情况测试

请按模块化方式组织代码。
```

---

## 📊 知识检查

### 自我评估

1. **为什么提示工程很重要？LLM 不是应该"理解"我吗？**

2. **设计优秀提示词的 5 大原则是什么？**

3. **如何使用"示例驱动"原则提高提示效果？**

4. **Chain-of-Thought 提示适用于什么场景？**

5. **常见的提示设计错误有哪些？如何避免？**

---

## 🎯 实践建议

### 提示词开发流程

```
1. 明确目标
   ↓
   我想要什么输出？

2. 提供上下文
   ↓
   LLM 需要知道什么？

3. 设计结构
   ↓
   如何组织提示词？

4. 添加示例
   ↓
   什么样的示例有帮助？

5. 设置约束
   ↓
   有什么限制条件？

6. 指定格式
   ↓
   期望什么样的输出？

7. 测试迭代
   ↓
   效果如何？如何改进？
```

### 提示词库管理

建议建立个人提示词库：

```
prompts/
├── code-generation/
│   ├── basic-function.md
│   ├── rest-api.md
│   └── algorithm.md
├── code-review/
│   ├── security.md
│   └── performance.md
├── debugging/
│   ├── error-analysis.md
│   └── fix-suggestion.md
└── documentation/
    ├── readme.md
    └── api-docs.md
```

### 版本控制

像管理代码一样管理提示词：

```bash
# 创建提示词版本
git commit -m "feat: add improved code review prompt v2.0"

# 对比不同版本
git diff prompt-v1.md prompt-v2.md

# A/B 测试
# 同时测试两个版本的提示效果
```

---

## 📚 延伸阅读

### 资源

1. [Anthropic Prompt Library](https://docs.anthropic.com/claude/prompt-library)
2. [OpenAI Prompt Engineering Guide](https://platform.openai.com/docs/guides/prompt-engineering)
3. [Learn Prompting](https://learnprompting.org/)

### 论文

1. "Language Models are Few-Shot Learners" (Brown et al., 2020)
2. "Chain-of-Thought Prompting Elicits Reasoning" (Wei et al., 2022)

---

**下一阅读**: [Prompt Engineering Guide](./03-prompt-engineering-guide.md)
