# Reading 2: Vercel AI SDK and Multi-stack Development
# Vercel AI SDK ä¸å¤šæ ˆå¼€å‘å®æˆ˜

> **Week 8 Reading #2**
> **ä¸»é¢˜**: æ·±å…¥æŒæ¡ Vercel AI SDK å’Œå¤šæŠ€æœ¯æ ˆçš„ AI åº”ç”¨å¼€å‘
> **é¢„è®¡é˜…è¯»æ—¶é—´**: 60-90 åˆ†é’Ÿ

---

## ğŸ“š å¯¼è¯»

Vercel AI SDK æ˜¯æ„å»º AI åŸç”Ÿåº”ç”¨çš„å¼ºå¤§å·¥å…·ï¼Œå®ƒæ”¯æŒå¤šç§æŠ€æœ¯æ ˆï¼Œæä¾›äº†æµå¼å“åº”ã€å·¥å…·è°ƒç”¨ç­‰é«˜çº§åŠŸèƒ½ã€‚æœ¬æ–‡å…¨é¢ä»‹ç» Vercel AI SDK çš„å®æˆ˜åº”ç”¨ï¼Œå¸®åŠ©ä½ ï¼š

1. **æŒæ¡æ ¸å¿ƒ** - Vercel AI SDK çš„æ ¸å¿ƒåŠŸèƒ½å’Œ API
2. **å¤šæ ˆæ”¯æŒ** - åœ¨ä¸åŒæ¡†æ¶ä¸­ä½¿ç”¨ AI SDK
3. **é«˜çº§ç‰¹æ€§** - æµå¼å“åº”ã€å·¥å…·è°ƒç”¨ã€å¤šæ¨¡æ€
4. **å®æˆ˜é¡¹ç›®** - æ„å»ºå®Œæ•´çš„ AI åº”ç”¨

---

## ğŸ¯ å­¦ä¹ ç›®æ ‡

é˜…è¯»å®Œæœ¬æ–‡åï¼Œä½ åº”è¯¥èƒ½å¤Ÿï¼š

- âœ… ç†Ÿç»ƒä½¿ç”¨ Vercel AI SDK çš„æ ¸å¿ƒ API
- âœ… åœ¨å¤šä¸ªæŠ€æœ¯æ ˆä¸­é›†æˆ AI èƒ½åŠ›
- âœ… å®ç°æµå¼å“åº”å’Œå·¥å…·è°ƒç”¨
- âœ… æ„å»ºç”Ÿäº§çº§åˆ«çš„ AI åº”ç”¨
- âœ… éƒ¨ç½²å’Œä¼˜åŒ– AI åº”ç”¨

---

## ç¬¬ä¸€éƒ¨åˆ†ï¼šVercel AI SDK æ ¸å¿ƒæ¦‚å¿µ

### 1. æ¶æ„æ¦‚è§ˆ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          åº”ç”¨å±‚ (Framework)              â”‚
â”‚  React / Vue / Svelte / Next.js / Nuxt  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         AI SDK å±‚                       â”‚
â”‚  - useChat()                            â”‚
â”‚  - useCompletion()                      â”‚
â”‚  - streamText()                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      AI æ¨¡å‹å±‚ (Provider)               â”‚
â”‚  - OpenAI (GPT-4, GPT-3.5)             â”‚
â”‚  - Anthropic (Claude)                   â”‚
â”‚  - Google (Gemini)                      â”‚
â”‚  - Mistral                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. æ ¸å¿ƒç»„ä»¶

```typescript
// æ ¸å¿ƒç»„ä»¶å…³ç³»å›¾

AI SDK
â”œâ”€â”€ Hooks (React)
â”‚   â”œâ”€â”€ useChat()         - èŠå¤©ç•Œé¢
â”‚   â”œâ”€â”€ useCompletion()   - æ–‡æœ¬è¡¥å…¨
â”‚   â””â”€â”€ useAssistant()    - AI åŠ©æ‰‹
â”‚
â”œâ”€â”€ API Routes
â”‚   â”œâ”€â”€ streamText()      - æµå¼æ–‡æœ¬
â”‚   â”œâ”€â”€ streamObject()    - æµå¼å¯¹è±¡
â”‚   â””â”€â”€ generateText()    - ç”Ÿæˆæ–‡æœ¬
â”‚
â”œâ”€â”€ Tools
â”‚   â”œâ”€â”€ Tool Call         - å·¥å…·è°ƒç”¨
â”‚   â””â”€â”€ Function Calling  - å‡½æ•°è°ƒç”¨
â”‚
â””â”€â”€ Providers
    â”œâ”€â”€ openai           - OpenAI
    â”œâ”€â”€ anthropic        - Anthropic
    â”œâ”€â”€ google           - Google
    â””â”€â”€ mistral          - Mistral AI
```

---

## ç¬¬äºŒéƒ¨åˆ†ï¼šæ ¸å¿ƒ API è¯¦è§£

### 1. useChat Hook

#### åŸºç¡€ç”¨æ³•

```typescript
import { useChat } from 'ai/react'

export default function Chat() {
  const { messages, input, handleInputChange, handleSubmit } = useChat()

  return (
    <div>
      {/* æ¶ˆæ¯åˆ—è¡¨ */}
      {messages.map(message => (
        <div key={message.id}>
          <strong>{message.role}:</strong>
          <p>{message.content}</p>
        </div>
      ))}

      {/* è¾“å…¥è¡¨å• */}
      <form onSubmit={handleSubmit}>
        <input
          value={input}
          onChange={handleInputChange}
          placeholder="è¾“å…¥æ¶ˆæ¯..."
        />
        <button type="submit">å‘é€</button>
      </form>
    </div>
  )
}
```

#### é«˜çº§é…ç½®

```typescript
const { messages, input, handleInputChange, handleSubmit, isLoading, error } = useChat({
  // API ç«¯ç‚¹
  api: '/api/chat',

  // åˆå§‹æ¶ˆæ¯
  initialMessages: [
    {
      id: '1',
      role: 'system',
      content: 'ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„åŠ©æ‰‹'
    }
  ],

  // è¯·æ±‚å‰çš„å›è°ƒ
  onRequest: async (messages) => {
    console.log('å‘é€æ¶ˆæ¯:', messages)
  },

  // å“åº”å®Œæˆçš„å›è°ƒ
  onResponse: (response) => {
    console.log('å“åº”çŠ¶æ€:', response.status)
  },

  // å®Œæˆçš„å›è°ƒ
  onFinish: (message) => {
    console.log('æ¶ˆæ¯å®Œæˆ:', message)
  },

  // é”™è¯¯å¤„ç†
  onError: (error) => {
    console.error('èŠå¤©é”™è¯¯:', error)
  },

  // é¢å¤–çš„è¯·æ±‚å¤´
  headers: {
    'X-Custom-Header': 'value'
  },

  // é¢å¤–çš„è¯·æ±‚ä½“
  body: {
    userId: '123'
  }
})
```

### 2. useCompletion Hook

```typescript
import { useCompletion } from 'ai/react'

export default function Completion() {
  const {
    completion,
    input,
    handleInputChange,
    handleSubmit,
    isLoading,
    error
  } = useCompletion({
    api: '/api/completion'
  })

  return (
    <div>
      <textarea
        value={input}
        onChange={handleInputChange}
        placeholder="è¾“å…¥æç¤ºè¯..."
      />

      <button onClick={handleSubmit} disabled={isLoading}>
        {isLoading ? 'ç”Ÿæˆä¸­...' : 'ç”Ÿæˆ'}
      </button>

      {error && <div className="error">{error.message}</div>}

      <div className="result">
        <strong>ç”Ÿæˆç»“æœ:</strong>
        <p>{completion}</p>
      </div>
    </div>
  )
}
```

### 3. æœåŠ¡ç«¯ API

#### streamText

```typescript
// app/api/chat/route.ts
import { openai } from '@ai-sdk/openai'
import { streamText } from 'ai'

export async function POST(req: Request) {
  const { messages } = await req.json()

  const stream = await streamText({
    model: openai('gpt-4-turbo'),
    messages,
    temperature: 0.7,
    maxTokens: 1000,
  })

  return stream.toAIStreamResponse()
}
```

#### generateText

```typescript
import { openai } from '@ai-sdk/openai'
import { generateText } from 'ai'

export async function POST(req: Request) {
  const { prompt } = await req.json()

  const { text } = await generateText({
    model: openai('gpt-4'),
    prompt,
    temperature: 0.7,
  })

  return Response.json({ text })
}
```

---

## ç¬¬ä¸‰éƒ¨åˆ†ï¼šå¤šæŠ€æœ¯æ ˆæ”¯æŒ

### 1. Next.js (React)

#### App Router é›†æˆ

```typescript
// app/api/chat/route.ts
import { openai } from '@ai-sdk/openai'
import { streamText } from 'ai'

export async function POST(req: Request) {
  const { messages } = await req.json()

  const result = await streamText({
    model: openai('gpt-4'),
    messages,
  })

  return result.toDataStreamResponse()
}

// app/page.tsx
'use client'

import { useChat } from 'ai/react'

export default function Page() {
  const { messages, input, handleInputChange, handleSubmit } = useChat()

  return (
    <main>
      {messages.map(m => (
        <div key={m.id}>
          {m.role === 'user' ? 'User: ' : 'AI: '}
          {m.content}
        </div>
      ))}

      <form onSubmit={handleSubmit}>
        <input value={input} onChange={handleInputChange} />
        <button>Send</button>
      </form>
    </main>
  )
}
```

### 2. Vue (Nuxt)

```vue
<!-- composables/useChat.ts -->
import { useChat as useAiChat } from 'ai/vue'

export function useChat() {
  const { messages, input, handleSubmit, isLoading } = useAiChat({
    api: '/api/chat'
  })

  return {
    messages,
    input,
    handleSubmit,
    isLoading
  }
}

<!-- components/Chat.vue -->
<template>
  <div>
    <div v-for="message in messages" :key="message.id">
      <strong>{{ message.role }}:</strong>
      <p>{{ message.content }}</p>
    </div>

    <form @submit="handleSubmit">
      <input v-model="input" />
      <button :disabled="isLoading">Send</button>
    </form>
  </div>
</template>

<script setup lang="ts">
import { useChat } from '@/composables/useChat'

const { messages, input, handleSubmit, isLoading } = useChat()
</script>
```

### 3. Svelte (SvelteKit)

```svelte
<!-- routes/api/chat/+server.ts -->
import { openai } from '@ai-sdk/openai'
import { streamText } from 'ai'
import type { RequestHandler } from './$types'

export const POST: RequestHandler = async ({ request }) => {
  const { messages } = await request.json()

  const stream = await streamText({
    model: openai('gpt-4'),
    messages,
  })

  return new Response(stream.toDataStream(), {
    headers: {
      'Content-Type': 'text/event-stream',
    },
  })
}

<!-- routes/+page.svelte -->
<script lang="ts">
  import { useChat } from 'ai/svelte'

  const { messages, input, handleSubmit, isLoading } = useChat({
    api: '/api/chat'
  })
</script>

<main>
  {#each $messages as message}
    <div>
      <strong>{message.role}:</strong>
      <p>{message.content}</p>
    </div>
  {/each}

  <form on:submit={handleSubmit}>
    <input bind:value={$input} />
    <button disabled={$isLoading}>Send</button>
  </form>
</main>
```

### 4. å…¶ä»–æ¡†æ¶

```typescript
// åŸç”Ÿ JavaScript/TypeScript
import { useChat } from 'ai/react'

// ä¹Ÿå¯ä»¥åœ¨ Vanilla JS ä¸­ä½¿ç”¨
```

---

## ç¬¬å››éƒ¨åˆ†ï¼šé«˜çº§ç‰¹æ€§

### 1. å·¥å…·è°ƒç”¨ (Tool Calling)

#### å®šä¹‰å·¥å…·

```typescript
import { openai } from '@ai-sdk/openai'
import { streamText } from 'ai'

// å®šä¹‰å·¥å…·
const tools = {
  weather: {
    description: 'è·å–å¤©æ°”ä¿¡æ¯',
    parameters: {
      type: 'object',
      properties: {
        location: {
          type: 'string',
          description: 'åŸå¸‚åç§°'
        },
        unit: {
          type: 'string',
          enum: ['celsius', 'fahrenheit'],
          description: 'æ¸©åº¦å•ä½'
        }
      },
      required: ['location']
    },
    execute: async ({ location, unit = 'celsius' }) => {
      // è°ƒç”¨å¤©æ°” API
      const response = await fetch(
        `https://api.weather.com/?location=${location}&unit=${unit}`
      )
      return response.json()
    }
  },

  time: {
    description: 'è·å–å½“å‰æ—¶é—´',
    parameters: {
      type: 'object',
      properties: {
        timezone: {
          type: 'string',
          description: 'æ—¶åŒºï¼Œå¦‚ Asia/Shanghai'
        }
      }
    },
    execute: async ({ timezone = 'UTC' }) => {
      return new Date().toLocaleString('zh-CN', { timeZone: timezone })
    }
  }
}

// ä½¿ç”¨å·¥å…·
export async function POST(req: Request) {
  const { messages } = await req.json()

  const result = await streamText({
    model: openai('gpt-4'),
    messages,
    tools,
  })

  return result.toAIStreamResponse()
}
```

### 2. å¤šæ¨¡æ€æ”¯æŒ

```typescript
import { openai } from '@ai-sdk/openai'

export async function POST(req: Request) {
  const { prompt, image } = await req.json()

  const result = await generateText({
    model: openai('gpt-4-vision-preview'),
    messages: [
      {
        role: 'user',
        content: [
          { type: 'text', text: prompt },
          { type: 'image', image: image } // base64 æˆ– URL
        ]
      }
    ]
  })

  return Response.json({ text: result.text })
}
```

### 3. æµå¼ UI æ›´æ–°

```typescript
'use client'

import { useChat } from 'ai/react'
import { useState } from 'react'

export default function StreamingChat() {
  const { messages, input, handleInputChange, handleSubmit } = useChat()
  const [streamedContent, setStreamedContent] = useState('')

  return (
    <div>
      {messages.map(message => (
        <div key={message.id}>
          {message.role === 'assistant' && (
            <div>
              <p>{message.content}</p>
              {/* å®æ—¶æµå¼æ›´æ–° */}
              {message.content === streamedContent && (
                <span className="cursor">|</span>
              )}
            </div>
          )}
        </div>
      ))}

      <form onSubmit={handleSubmit}>
        <input
          value={input}
          onChange={handleInputChange}
          placeholder="è¾“å…¥æ¶ˆæ¯..."
        />
      </form>
    </div>
  )
}
```

---

## ç¬¬äº”éƒ¨åˆ†ï¼šå®æˆ˜é¡¹ç›®

### é¡¹ç›®: AI å®¢æœåŠ©æ‰‹

#### åŠŸèƒ½éœ€æ±‚

```markdown
1. æ™ºèƒ½å¯¹è¯
   - ä¸Šä¸‹æ–‡è®°å¿†
   - å¤šè½®å¯¹è¯
   - æƒ…æ„Ÿç†è§£

2. çŸ¥è¯†åº“é›†æˆ
   - äº§å“ä¿¡æ¯æŸ¥è¯¢
   - å¸¸è§é—®é¢˜è§£ç­”
   - è®¢å•æŸ¥è¯¢

3. äººå·¥è½¬æ¥
   - è‡ªåŠ¨åˆ¤æ–­å¤æ‚é—®é¢˜
   - äººå·¥å®¢æœå¯¹æ¥
   - å¯¹è¯å†å²åŒæ­¥

4. å¤šæ¸ é“æ”¯æŒ
   - Web èŠå¤©
   - ç§»åŠ¨åº”ç”¨
   - ç¤¾äº¤åª’ä½“
```

#### å®ç°ä»£ç 

```typescript
// lib/ai-knowledge-base.ts
const knowledgeBase = {
  products: [
    {
      id: '1',
      name: 'äº§å“ A',
      description: '...',
      price: 99.99
    }
    // ...
  ],

  faqs: [
    {
      question: 'å¦‚ä½•é€€æ¬¾ï¼Ÿ',
      answer: 'æ‚¨å¯ä»¥åœ¨è®¢å•é¡µé¢ç”³è¯·é€€æ¬¾...'
    }
    // ...
  ]
}

// æŸ¥æ‰¾å·¥å…·
const searchTools = {
  searchProducts: {
    description: 'æœç´¢äº§å“ä¿¡æ¯',
    parameters: {
      type: 'object',
      properties: {
        query: { type: 'string' }
      }
    },
    execute: async ({ query }) => {
      return knowledgeBase.products.filter(p =>
        p.name.includes(query) || p.description.includes(query)
      )
    }
  },

  searchFAQ: {
    description: 'æœç´¢å¸¸è§é—®é¢˜',
    parameters: {
      type: 'object',
      properties: {
        query: { type: 'string' }
      }
    },
    execute: async ({ query }) => {
      return knowledgeBase.faqs.filter(faq =>
        faq.question.includes(query)
      )
    }
  }
}

// app/api/customer-service/route.ts
import { openai } from '@ai-sdk/openai'
import { streamText } from 'ai'

export async function POST(req: Request) {
  const { messages } = await req.json()

  const result = await streamText({
    model: openai('gpt-4'),
    system: `ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å®¢æœåŠ©æ‰‹ã€‚
    ä½ å¯ä»¥ï¼š
    1. å›ç­”å¸¸è§é—®é¢˜
    2. æŸ¥è¯¢äº§å“ä¿¡æ¯
    3. ååŠ©è®¢å•å¤„ç†
    4. åœ¨å¿…è¦æ—¶è½¬æ¥äººå·¥å®¢æœ`,

    messages,
    tools: searchTools,
  })

  return result.toAIStreamResponse()
}
```

---

## ç¬¬å…­éƒ¨åˆ†ï¼šéƒ¨ç½²å’Œä¼˜åŒ–

### 1. Vercel éƒ¨ç½²

```bash
# 1. å®‰è£…ä¾èµ–
npm install ai @ai-sdk/openai

# 2. é…ç½®ç¯å¢ƒå˜é‡
# .env.local
OPENAI_API_KEY=sk-...

# 3. éƒ¨ç½²
vercel

# æˆ–ä½¿ç”¨ GitHub é›†æˆè‡ªåŠ¨éƒ¨ç½²
git push origin main
```

### 2. æ€§èƒ½ä¼˜åŒ–

```typescript
// ä½¿ç”¨æµå¼å“åº”å‡å°‘å»¶è¿Ÿ
const stream = await streamText({
  model: openai('gpt-4'),
  messages,
  // å‡å°‘æœ€å¤§ token æ•°
  maxTokens: 500,
  // é™ä½æ¸©åº¦ä»¥åŠ å¿«å“åº”
  temperature: 0.5,
})

// ä½¿ç”¨ç¼“å­˜
const cached = await cache.get(`chat:${userId}`)
if (cached) {
  return Response.json(cached)
}

// ä½¿ç”¨ Edge Runtime
export const runtime = 'edge'
```

---

## ğŸ“Š çŸ¥è¯†æ£€æŸ¥

1. **Vercel AI SDK çš„æ ¸å¿ƒç»„ä»¶æœ‰å“ªäº›ï¼Ÿ**

2. **å¦‚ä½•åœ¨ä¸åŒæŠ€æœ¯æ ˆä¸­ä½¿ç”¨ AI SDKï¼Ÿ**

3. **å¦‚ä½•å®ç°å·¥å…·è°ƒç”¨ï¼Ÿ**

4. **å¦‚ä½•ä¼˜åŒ– AI åº”ç”¨çš„æ€§èƒ½ï¼Ÿ**

---

## ğŸ“š å»¶ä¼¸é˜…è¯»

1. [Vercel AI SDK æ–‡æ¡£](https://sdk.vercel.ai)
2. [Next.js AI æ–‡æ¡£](https://nextjs.org/docs/app/building-your-application/configuring/ai)
3. [AI Recipes](https://sdk.vercel.ai/docs/ai-sdk/ui/recipes)

---

**è¯¾ç¨‹æ€»ç»“**: Vercel AI SDK æ˜¯æ„å»ºç°ä»£ AI åº”ç”¨çš„å¼ºå¤§å·¥å…·ã€‚é€šè¿‡æŒæ¡å…¶æ ¸å¿ƒ API å’Œå¤šæŠ€æœ¯æ ˆæ”¯æŒï¼Œä½ å¯ä»¥å¿«é€Ÿæ„å»ºç”Ÿäº§çº§åˆ«çš„ AI åº”ç”¨ã€‚

**ä¸‹ä¸€æ­¥**: æ„å»ºä½ è‡ªå·±çš„ AI åº”ç”¨ï¼
