# Reading 2: Automated Incident Response and Self-Healing Systems
# è‡ªåŠ¨åŒ–äº‹ä»¶å“åº”ä¸è‡ªæ„ˆåˆç³»ç»Ÿ

> **Week 9 Reading #2**
> **ä¸»é¢˜**: æŒæ¡ AI é©±åŠ¨çš„è‡ªåŠ¨åŒ–äº‹ä»¶å“åº”å’Œè‡ªæ„ˆåˆç³»ç»Ÿè®¾è®¡
> **é¢„è®¡é˜…è¯»æ—¶é—´**: 75-90 åˆ†é’Ÿ

---

## ğŸ“š å¯¼è¯»

ä¼ ç»Ÿçš„äº‹ä»¶å“åº”æ˜¯"å‘ç°é—®é¢˜ â†’ äººå·¥è¯Šæ–­ â†’ æ‰‹åŠ¨ä¿®å¤"çš„æ¼«é•¿è¿‡ç¨‹ã€‚åœ¨ AI æ—¶ä»£ï¼Œæˆ‘ä»¬å¯ä»¥æ„å»ºè‡ªæ„ˆåˆç³»ç»Ÿï¼Œå®ç°"æ£€æµ‹ â†’ åˆ†æ â†’ ä¿®å¤ â†’ éªŒè¯"çš„å…¨è‡ªåŠ¨åŒ–æµç¨‹ã€‚æœ¬æ–‡å…¨é¢ä»‹ç»è‡ªåŠ¨åŒ–äº‹ä»¶å“åº”çš„å®Œæ•´ä½“ç³»ï¼Œå¸®åŠ©ä½ ï¼š

1. **ç†è§£æµç¨‹** - äº‹ä»¶å“åº”çš„äº”ä¸ªé˜¶æ®µ
2. **è®¾è®¡ç³»ç»Ÿ** - è‡ªæ„ˆåˆç³»ç»Ÿçš„æ¶æ„è®¾è®¡
3. **å®ç°è‡ªåŠ¨åŒ–** - AI é©±åŠ¨çš„å†³ç­–å’Œæ‰§è¡Œ
4. **å®è·µè½åœ°** - çœŸå®åœºæ™¯çš„å®Œæ•´å®ç°

---

## ğŸ¯ å­¦ä¹ ç›®æ ‡

é˜…è¯»å®Œæœ¬æ–‡åï¼Œä½ åº”è¯¥èƒ½å¤Ÿï¼š

- âœ… ç†è§£äº‹ä»¶å“åº”çš„å®Œæ•´ç”Ÿå‘½å‘¨æœŸ
- âœ… è®¾è®¡è‡ªæ„ˆåˆç³»ç»Ÿçš„æ¶æ„
- âœ… å®ç° AI é©±åŠ¨çš„è‡ªåŠ¨åŒ–ä¿®å¤
- âœ… æ„å»ºå®‰å…¨çš„è‡ªåŠ¨åŒ–äº‹ä»¶å“åº”å¹³å°
- âœ… åœ¨ç”Ÿäº§ç¯å¢ƒä¸­å®æ–½è‡ªæ„ˆåˆèƒ½åŠ›

---

## ç¬¬ä¸€éƒ¨åˆ†ï¼šè‡ªåŠ¨åŒ–äº‹ä»¶å“åº”çš„äº”ä¸ªé˜¶æ®µ

### å®Œæ•´æµç¨‹å›¾

```python
"""
è‡ªåŠ¨åŒ–äº‹ä»¶å“åº”çš„äº”é˜¶æ®µæµç¨‹:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ é˜¶æ®µ 1: æ£€æµ‹ (Detect)                                       â”‚
â”‚ - ç›‘æ§ç³»ç»Ÿå’Œåº”ç”¨                                            â”‚
â”‚ - è¯†åˆ«å¼‚å¸¸å’Œæ•…éšœ                                            â”‚
â”‚ - è¯„ä¼°å½±å“èŒƒå›´                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ é˜¶æ®µ 2: åˆ†ç±» (Classify)                                     â”‚
â”‚ - ç¡®å®šäº‹ä»¶ç±»å‹                                              â”‚
â”‚ - è¯„ä¼°ä¸¥é‡ç¨‹åº¦ (CRITICAL/HIGH/MEDIUM/LOW)                   â”‚
â”‚ - åˆ¤æ–­å½±å“èŒƒå›´å’Œä¼˜å…ˆçº§                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ é˜¶æ®µ 3: å†³ç­– (Decide)                                       â”‚
â”‚ - AI åˆ†ææ ¹æœ¬åŸå›                                             â”‚
â”‚ - è¯„ä¼°ä¿®å¤æ–¹æ¡ˆ                                              â”‚
â”‚ - é€‰æ‹©æœ€ä½³ç­–ç•¥                                              â”‚
â”‚ - éªŒè¯å®‰å…¨æ€§                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ é˜¶æ®µ 4: æ‰§è¡Œ (Execute)                                      â”‚
â”‚ - æ‰§è¡Œè‡ªåŠ¨åŒ–ä¿®å¤                                            â”‚
â”‚ - åè°ƒå¤šä¸ªæœåŠ¡                                              â”‚
â”‚ - åº”ç”¨é…ç½®å˜æ›´                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ é˜¶æ®µ 5: éªŒè¯ (Verify)                                       â”‚
â”‚ - ç¡®è®¤é—®é¢˜å·²è§£å†³                                            â”‚
â”‚ - éªŒè¯ç³»ç»Ÿå¥åº·åº¦                                            â”‚
â”‚ - è®°å½•äº‹ä»¶å’Œå¤„ç†è¿‡ç¨‹                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
"""

class AutomatedIncidentResponse:
    """è‡ªåŠ¨åŒ–äº‹ä»¶å“åº”ç³»ç»Ÿ"""

    def __init__(self):
        self.detector = AnomalyDetector()      # é˜¶æ®µ 1
        self.classifier = EventClassifier()    # é˜¶æ®µ 2
        self.decider = AIDecisionEngine()      # é˜¶æ®µ 3
        self.executor = AutomationExecutor()   # é˜¶æ®µ 4
        self.verifier = HealthVerifier()       # é˜¶æ®µ 5

    def handle_incident(self, event: dict) -> dict:
        """å¤„ç†äº‹ä»¶ï¼ˆå®Œæ•´æµç¨‹ï¼‰"""

        # é˜¶æ®µ 1: æ£€æµ‹
        detection = self.detector.detect(event)
        if not detection["is_anomaly"]:
            return {"action": "none", "reason": "Not an anomaly"}

        # é˜¶æ®µ 2: åˆ†ç±»
        classification = self.classifier.classify(event, detection)

        # é˜¶æ®µ 3: å†³ç­–
        decision = self.decider.decide(event, classification)

        if decision["confidence"] < 0.8:
            # ç½®ä¿¡åº¦ä½ï¼Œéœ€è¦äººå·¥ä»‹å…¥
            return {
                "action": "human_intervention",
                "reason": "Low confidence",
                "decision": decision
            }

        # é˜¶æ®µ 4: æ‰§è¡Œ
        execution = self.executor.execute(decision)

        # é˜¶æ®µ 5: éªŒè¯
        verification = self.verifier.verify(event, execution)

        return {
            "action": "auto_remediated",
            "detection": detection,
            "classification": classification,
            "decision": decision,
            "execution": execution,
            "verification": verification
        }
```

---

## ç¬¬äºŒéƒ¨åˆ†ï¼šé˜¶æ®µè¯¦è§£

### é˜¶æ®µ 1: æ£€æµ‹ (Detect)

#### å¼‚å¸¸æ£€æµ‹å®ç°

```python
class AnomalyDetector:
    """å¼‚å¸¸æ£€æµ‹å™¨"""

    def __init__(self):
        self.metrics_history = []
        self.anomaly_thresholds = {
            "error_rate": 0.05,        # é”™è¯¯ç‡ > 5%
            "latency_p95": 1000,       # P95 å»¶è¿Ÿ > 1s
            "cpu_usage": 90,           # CPU ä½¿ç”¨ç‡ > 90%
            "memory_usage": 85,        # å†…å­˜ä½¿ç”¨ç‡ > 85%
        }

    def detect(self, event: dict) -> dict:
        """æ£€æµ‹äº‹ä»¶æ˜¯å¦å¼‚å¸¸"""

        metrics = event.get("metrics", {})
        anomalies = []

        # æ£€æŸ¥é”™è¯¯ç‡
        if "error_rate" in metrics:
            error_rate = metrics["error_rate"]
            if error_rate > self.anomaly_thresholds["error_rate"]:
                anomalies.append({
                    "metric": "error_rate",
                    "value": error_rate,
                    "threshold": self.anomaly_thresholds["error_rate"],
                    "severity": "HIGH" if error_rate > 0.1 else "MEDIUM"
                })

        # æ£€æŸ¥å»¶è¿Ÿ
        if "latency_p95" in metrics:
            latency_p95 = metrics["latency_p95"]
            if latency_p95 > self.anomaly_thresholds["latency_p95"]:
                anomalies.append({
                    "metric": "latency_p95",
                    "value": latency_p95,
                    "threshold": self.anomaly_thresholds["latency_p95"],
                    "severity": "HIGH" if latency_p95 > 2000 else "MEDIUM"
                })

        # æ£€æŸ¥èµ„æºä½¿ç”¨
        for resource in ["cpu_usage", "memory_usage"]:
            if resource in metrics:
                value = metrics[resource]
                if value > self.anomaly_thresholds[resource]:
                    anomalies.append({
                        "metric": resource,
                        "value": value,
                        "threshold": self.anomaly_thresholds[resource],
                        "severity": "HIGH" if value > 95 else "MEDIUM"
                    })

        # åˆ¤æ–­æ˜¯å¦å¼‚å¸¸
        is_anomaly = len(anomalies) > 0

        return {
            "is_anomaly": is_anomaly,
            "anomalies": anomalies,
            "timestamp": time.time()
        }

# ä½¿ç”¨ç¤ºä¾‹
detector = AnomalyDetector()

event = {
    "service": "ai-chat-service",
    "metrics": {
        "error_rate": 0.12,      # 12% é”™è¯¯ç‡ï¼ˆå¼‚å¸¸ï¼‰
        "latency_p95": 850,      # 850ms å»¶è¿Ÿï¼ˆæ­£å¸¸ï¼‰
        "cpu_usage": 92,         # 92% CPUï¼ˆå¼‚å¸¸ï¼‰
        "memory_usage": 78,      # 78% å†…å­˜ï¼ˆæ­£å¸¸ï¼‰
    }
}

detection = detector.detect(event)

if detection["is_anomaly"]:
    print(f"å‘ç°å¼‚å¸¸ï¼")
    for anomaly in detection["anomalies"]:
        print(f"  - {anomaly['metric']}: {anomaly['value']} (é˜ˆå€¼: {anomaly['threshold']})")
        print(f"    ä¸¥é‡ç¨‹åº¦: {anomaly['severity']}")
```

---

### é˜¶æ®µ 2: åˆ†ç±» (Classify)

#### äº‹ä»¶åˆ†ç±»å™¨

```python
class EventClassifier:
    """äº‹ä»¶åˆ†ç±»å™¨"""

    def __init__(self):
        self.event_types = {
            "high_error_rate": "error_rate > 0.1",
            "high_latency": "latency_p95 > 1000ms",
            "resource_exhaustion": "cpu_usage > 90% or memory_usage > 85%",
            "service_down": "health_check == false",
            "api_rate_limit": "error_type == 'RateLimitError'",
            "database_connection": "error_type == 'ConnectionError'",
        }

        self.severity_matrix = {
            ("high_error_rate", True): "CRITICAL",     # é«˜é”™è¯¯ç‡ + å½±å“ç”¨æˆ· = CRITICAL
            ("high_error_rate", False): "HIGH",        # é«˜é”™è¯¯ç‡ + ä¸å½±å“ç”¨æˆ· = HIGH
            ("high_latency", True): "HIGH",            # é«˜å»¶è¿Ÿ + å½±å“ç”¨æˆ· = HIGH
            ("high_latency", False): "MEDIUM",         # é«˜å»¶è¿Ÿ + ä¸å½±å“ç”¨æˆ· = MEDIUM
            ("resource_exhaustion", True): "HIGH",     # èµ„æºè€—å°½ + å½±å“ç”¨æˆ· = HIGH
            ("service_down", True): "CRITICAL",        # æœåŠ¡å®•æœº = CRITICAL
            ("api_rate_limit", True): "MEDIUM",        # API é™æµ = MEDIUM
        }

    def classify(self, event: dict, detection: dict) -> dict:
        """åˆ†ç±»äº‹ä»¶"""

        anomalies = detection["anomalies"]
        affects_users = event.get("affects_users", True)

        # ç¡®å®šäº‹ä»¶ç±»å‹
        event_type = self._determine_event_type(anomalies, event)

        # ç¡®å®šä¸¥é‡ç¨‹åº¦
        severity = self._determine_severity(event_type, affects_users)

        # ç¡®å®šå½±å“èŒƒå›´
        impact = self._assess_impact(event, detection)

        # ç¡®å®šä¼˜å…ˆçº§
        priority = self._calculate_priority(severity, impact)

        return {
            "event_type": event_type,
            "severity": severity,
            "impact": impact,
            "priority": priority,
            "affects_users": affects_users,
            "requires_immediate_action": severity in ["CRITICAL", "HIGH"],
        }

    def _determine_event_type(self, anomalies: list, event: dict) -> str:
        """ç¡®å®šäº‹ä»¶ç±»å‹"""

        # æ£€æŸ¥ç‰¹å®šé”™è¯¯ç±»å‹
        if "error_type" in event:
            error_type = event["error_type"]
            if error_type == "RateLimitError":
                return "api_rate_limit"
            elif error_type == "ConnectionError":
                return "database_connection"

        # åŸºäºå¼‚å¸¸æŒ‡æ ‡åˆ¤æ–­
        for anomaly in anomalies:
            metric = anomaly["metric"]
            if metric == "error_rate":
                return "high_error_rate"
            elif metric == "latency_p95":
                return "high_latency"
            elif metric in ["cpu_usage", "memory_usage"]:
                return "resource_exhaustion"

        # æ£€æŸ¥æœåŠ¡å¥åº·çŠ¶æ€
        if event.get("health_check") == False:
            return "service_down"

        return "unknown"

    def _determine_severity(self, event_type: str, affects_users: bool) -> str:
        """ç¡®å®šä¸¥é‡ç¨‹åº¦"""
        key = (event_type, affects_users)
        return self.severity_matrix.get(key, "MEDIUM")

    def _assess_impact(self, event: dict, detection: dict) -> dict:
        """è¯„ä¼°å½±å“èŒƒå›´"""

        service = event.get("service", "unknown")
        affected_users = event.get("affected_users_count", 0)

        # ä¼°ç®—ä¸šåŠ¡å½±å“
        if affected_users > 1000:
            business_impact = "HIGH"
        elif affected_users > 100:
            business_impact = "MEDIUM"
        else:
            business_impact = "LOW"

        return {
            "service": service,
            "affected_users": affected_users,
            "business_impact": business_impact,
            "estimated_revenue_loss": self._estimate_revenue_loss(event),
        }

    def _estimate_revenue_loss(self, event: dict) -> float:
        """ä¼°ç®—æ”¶å…¥æŸå¤±ï¼ˆç¤ºä¾‹ï¼‰"""
        # è¿™é‡Œå¯ä»¥ä½¿ç”¨æ›´å¤æ‚çš„æ¨¡å‹
        affected_users = event.get("affected_users_count", 0)
        downtime_hours = event.get("downtime_hours", 0)
        avg_revenue_per_user_per_hour = 0.1  # ç¤ºä¾‹å€¼

        return affected_users * downtime_hours * avg_revenue_per_user_per_hour

    def _calculate_priority(self, severity: str, impact: dict) -> int:
        """è®¡ç®—ä¼˜å…ˆçº§ï¼ˆ1-10ï¼Œ10 æœ€é«˜ï¼‰"""

        base_priority = {
            "CRITICAL": 9,
            "HIGH": 7,
            "MEDIUM": 5,
            "LOW": 3,
        }[severity]

        business_impact = impact["business_impact"]
        if business_impact == "HIGH":
            base_priority = min(10, base_priority + 1)
        elif business_impact == "LOW":
            base_priority = max(1, base_priority - 1)

        return base_priority

# ä½¿ç”¨ç¤ºä¾‹
classifier = EventClassifier()

classification = classifier.classify(event, detection)

print(f"äº‹ä»¶ç±»å‹: {classification['event_type']}")
print(f"ä¸¥é‡ç¨‹åº¦: {classification['severity']}")
print(f"å½±å“èŒƒå›´: {classification['impact']}")
print(f"ä¼˜å…ˆçº§: {classification['priority']}/10")
print(f"éœ€è¦ç«‹å³è¡ŒåŠ¨: {classification['requires_immediate_action']}")
```

---

### é˜¶æ®µ 3: å†³ç­– (Decide)

#### AI å†³ç­–å¼•æ“

```python
class AIDecisionEngine:
    """AI å†³ç­–å¼•æ“"""

    def __init__(self, api_key: str):
        self.client = openai.OpenAI(api_key=api_key)
        self.remediation_strategies = {
            "high_error_rate": [
                "restart_service",
                "rollback_deployment",
                "scale_up",
            ],
            "high_latency": [
                "scale_up",
                "optimize_database",
                "enable_caching",
            ],
            "resource_exhaustion": [
                "scale_up",
                "restart_service",
                "cleanup_resources",
            ],
            "api_rate_limit": [
                "implement_exponential_backoff",
                "switch_to_backup_provider",
                "enable_caching",
            ],
            "database_connection": [
                "restart_database",
                "switch_to_standby",
                "enable_connection_pooling",
            ],
        }

    def decide(self, event: dict, classification: dict) -> dict:
        """AI é©±åŠ¨çš„å†³ç­–"""

        # è·å–å¯èƒ½çš„ç­–ç•¥
        event_type = classification["event_type"]
        possible_strategies = self.remediation_strategies.get(event_type, [])

        # æ„å»ºå†³ç­– Prompt
        prompt = self._build_decision_prompt(event, classification, possible_strategies)

        # è°ƒç”¨ AI
        try:
            response = self.client.chat.completions.create(
                model="gpt-4",
                messages=[
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ SRE å·¥ç¨‹å¸ˆï¼Œè´Ÿè´£å†³ç­–äº‹ä»¶å“åº”ç­–ç•¥ã€‚"
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=0.2,  # ä½æ¸©åº¦ï¼Œå‡å°‘éšæœºæ€§
                response_format={"type": "json_object"}
            )

            decision = json.loads(response.choices[0].message.content)

            # éªŒè¯å†³ç­–å®‰å…¨æ€§
            safety_check = self._safety_check(decision, event)

            return {
                "strategy": decision["strategy"],
                "reasoning": decision["reasoning"],
                "steps": decision["steps"],
                "estimated_success_rate": decision.get("estimated_success_rate", 0.8),
                "confidence": decision.get("confidence", 0.8),
                "safety_check": safety_check,
            }

        except Exception as e:
            logger.error("ai_decision_failed", error=str(e))
            # é™çº§åˆ°è§„åˆ™å¼•æ“
            return self._rule_based_decision(event, classification)

    def _build_decision_prompt(self, event: dict, classification: dict, strategies: list) -> str:
        """æ„å»ºå†³ç­– Prompt"""

        return f"""
åˆ†æä»¥ä¸‹äº‹ä»¶ï¼Œæ¨èæœ€ä½³çš„ä¿®å¤ç­–ç•¥ï¼š

äº‹ä»¶ä¿¡æ¯ï¼š
- æœåŠ¡: {event.get('service', 'unknown')}
- äº‹ä»¶ç±»å‹: {classification['event_type']}
- ä¸¥é‡ç¨‹åº¦: {classification['severity']}
- å½±å“ç”¨æˆ·: {classification['affects_users']}
- å—å½±å“ç”¨æˆ·æ•°: {classification['impact']['affected_users']}

å¯ç”¨çš„ä¿®å¤ç­–ç•¥ï¼š
{json.dumps(strategies, ensure_ascii=False)}

å½“å‰çŠ¶æ€ï¼š
- é”™è¯¯ç‡: {event.get('metrics', {}).get('error_rate', 'N/A')}
- P95 å»¶è¿Ÿ: {event.get('metrics', {}).get('latency_p95', 'N/A')}ms
- CPU ä½¿ç”¨ç‡: {event.get('metrics', {}).get('cpu_usage', 'N/A')}%
- å†…å­˜ä½¿ç”¨ç‡: {event.get('metrics', {}).get('memory_usage', 'N/A')}%

è¯·æä¾›ï¼š
1. æ¨èçš„ç­–ç•¥ï¼ˆä»ä¸Šè¿°ç­–ç•¥ä¸­é€‰æ‹©ä¸€ä¸ªï¼‰
2. ç†ç”±ï¼ˆä¸ºä»€ä¹ˆé€‰æ‹©è¿™ä¸ªç­–ç•¥ï¼‰
3. æ‰§è¡Œæ­¥éª¤ï¼ˆè¯¦ç»†çš„æ‰§è¡Œæ­¥éª¤ï¼‰
4. é¢„ä¼°æˆåŠŸç‡ï¼ˆ0-1ï¼‰
5. ç½®ä¿¡åº¦ï¼ˆ0-1ï¼‰

ä»¥ JSON æ ¼å¼è¿”å›ï¼š
{{
    "strategy": "ç­–ç•¥åç§°",
    "reasoning": "ç†ç”±",
    "steps": ["æ­¥éª¤1", "æ­¥éª¤2", ...],
    "estimated_success_rate": 0.9,
    "confidence": 0.85
}}
"""

    def _safety_check(self, decision: dict, event: dict) -> dict:
        """å®‰å…¨æ£€æŸ¥"""

        checks = []

        # æ£€æŸ¥ 1: æ˜¯å¦ä¼šå½±å“å…¶ä»–æœåŠ¡
        strategy = decision["strategy"]
        if strategy in ["scale_up", "restart_service"]:
            checks.append({
                "check": "impact_on_other_services",
                "status": "safe" if event.get("can_scale_safely", True) else "risky",
                "reason": "éœ€è¦æ£€æŸ¥èµ„æºå¯ç”¨æ€§"
            })

        # æ£€æŸ¥ 2: æ˜¯å¦ä¼šå¯¼è‡´æ•°æ®ä¸¢å¤±
        if strategy == "rollback_deployment":
            checks.append({
                "check": "data_loss_risk",
                "status": "safe",
                "reason": "å›æ»šä¸ä¼šå¯¼è‡´æ•°æ®ä¸¢å¤±"
            })

        # æ£€æŸ¥ 3: æ˜¯å¦å¯ä»¥å›æ»š
        checks.append({
            "check": "rollback_possible",
            "status": "safe",
            "reason": "æ‰€æœ‰æ“ä½œéƒ½å¯ä»¥å›æ»š"
        })

        # ç»¼åˆåˆ¤æ–­
        all_safe = all(c["status"] == "safe" for c in checks)

        return {
            "overall_status": "safe" if all_safe else "risky",
            "checks": checks,
            "can_proceed": all_safe
        }

    def _rule_based_decision(self, event: dict, classification: dict) -> dict:
        """åŸºäºè§„åˆ™çš„å†³ç­–ï¼ˆé™çº§æ–¹æ¡ˆï¼‰"""

        event_type = classification["event_type"]
        severity = classification["severity"]

        # ç®€å•çš„è§„åˆ™å¼•æ“
        if event_type == "high_error_rate" and severity == "CRITICAL":
            strategy = "rollback_deployment"
            reasoning = "ä¸¥é‡é”™è¯¯ç‡ï¼Œç«‹å³å›æ»šåˆ°ä¸Šä¸€ä¸ªç¨³å®šç‰ˆæœ¬"
        elif event_type == "resource_exhaustion":
            strategy = "scale_up"
            reasoning = "èµ„æºè€—å°½ï¼Œæ‰©å®¹ä»¥å¢åŠ å®¹é‡"
        elif event_type == "api_rate_limit":
            strategy = "implement_exponential_backoff"
            reasoning = "API é™æµï¼Œå®æ–½æŒ‡æ•°é€€é¿"
        else:
            strategy = "restart_service"
            reasoning = "é»˜è®¤ç­–ç•¥ï¼šé‡å¯æœåŠ¡"

        return {
            "strategy": strategy,
            "reasoning": reasoning,
            "steps": ["æ‰§è¡Œ " + strategy],
            "estimated_success_rate": 0.7,
            "confidence": 0.7,
            "safety_check": {"overall_status": "safe", "can_proceed": True},
            "decision_method": "rule_based"
        }

# ä½¿ç”¨ç¤ºä¾‹
decider = AIDecisionEngine(api_key=os.getenv("OPENAI_API_KEY"))

decision = decider.decide(event, classification)

print(f"æ¨èç­–ç•¥: {decision['strategy']}")
print(f"ç†ç”±: {decision['reasoning']}")
print(f"æ‰§è¡Œæ­¥éª¤: {decision['steps']}")
print(f"é¢„ä¼°æˆåŠŸç‡: {decision['estimated_success_rate']}")
print(f"ç½®ä¿¡åº¦: {decision['confidence']}")
print(f"å®‰å…¨æ£€æŸ¥: {decision['safety_check']['overall_status']}")
```

---

### é˜¶æ®µ 4: æ‰§è¡Œ (Execute)

#### è‡ªåŠ¨åŒ–æ‰§è¡Œå™¨

```python
class AutomationExecutor:
    """è‡ªåŠ¨åŒ–æ‰§è¡Œå™¨"""

    def __init__(self):
        self.kubernetes_client = self._init_kubernetes()
        self.remediation_scripts = {
            "restart_service": self.restart_service,
            "scale_up": self.scale_up,
            "rollback_deployment": self.rollback_deployment,
            "implement_exponential_backoff": self.implement_exponential_backoff,
            "switch_to_backup_provider": self.switch_to_backup_provider,
        }

    def execute(self, decision: dict) -> dict:
        """æ‰§è¡Œä¿®å¤ç­–ç•¥"""

        strategy = decision["strategy"]
        steps = decision.get("steps", [])

        execution_log = []

        try:
            # è®°å½•æ‰§è¡Œå¼€å§‹
            execution_log.append({
                "step": 0,
                "action": "start",
                "message": f"å¼€å§‹æ‰§è¡Œç­–ç•¥: {strategy}",
                "timestamp": time.time()
            })

            # æ‰§è¡Œç­–ç•¥
            if strategy in self.remediation_scripts:
                result = self.remediation_scripts[strategy]()
                execution_log.append({
                    "step": 1,
                    "action": "execute",
                    "message": f"æ‰§è¡Œ {strategy}",
                    "result": result,
                    "timestamp": time.time()
                })
            else:
                raise ValueError(f"Unknown strategy: {strategy}")

            # æ‰§è¡Œé¢å¤–æ­¥éª¤
            for i, step in enumerate(steps, start=2):
                execution_log.append({
                    "step": i,
                    "action": "additional_step",
                    "message": step,
                    "timestamp": time.time()
                })

            return {
                "status": "success",
                "strategy": strategy,
                "execution_log": execution_log,
                "duration": time.time() - execution_log[0]["timestamp"]
            }

        except Exception as e:
            logger.error("execution_failed", strategy=strategy, error=str(e))
            return {
                "status": "failed",
                "strategy": strategy,
                "error": str(e),
                "execution_log": execution_log
            }

    def restart_service(self) -> dict:
        """é‡å¯æœåŠ¡"""

        # ä½¿ç”¨ Kubernetes API é‡å¯ Pod
        namespace = "default"
        deployment = "ai-chat-service"

        # æ‰§è¡Œæ»šåŠ¨é‡å¯
        self.kubernetes_client.patch_namespaced_deployment(
            name=deployment,
            namespace=namespace,
            body={
                "spec": {
                    "template": {
                        "metadata": {
                            "annotations": {
                                "kubectl.kubernetes.io/restartedAt": time.time()
                            }
                        }
                    }
                }
            }
        )

        return {
            "action": "restart_service",
            "deployment": deployment,
            "namespace": namespace
        }

    def scale_up(self) -> dict:
        """æ‰©å®¹"""

        namespace = "default"
        deployment = "ai-chat-service"

        # è·å–å½“å‰å‰¯æœ¬æ•°
        current_deployment = self.kubernetes_client.read_namespaced_deployment(
            name=deployment,
            namespace=namespace
        )
        current_replicas = current_deployment.spec.replicas

        # å¢åŠ å‰¯æœ¬æ•°
        new_replicas = current_replicas + 2

        self.kubernetes_client.patch_namespaced_deployment_scale(
            name=deployment,
            namespace=namespace,
            body={"spec": {"replicas": new_replicas}}
        )

        return {
            "action": "scale_up",
            "from_replicas": current_replicas,
            "to_replicas": new_replicas
        }

    def rollback_deployment(self) -> dict:
        """å›æ»šéƒ¨ç½²"""

        namespace = "default"
        deployment = "ai-chat-service"

        # è·å–ä¸Šä¸€ä¸ªç‰ˆæœ¬
        # å®é™…å®ç°ä¸­ï¼Œåº”è¯¥ä»éƒ¨ç½²å†å²ä¸­é€‰æ‹©

        # æ‰§è¡Œå›æ»š
        self.kubernetes_client.rollback_deployment(
            name=deployment,
            namespace=namespace
        )

        return {
            "action": "rollback_deployment",
            "deployment": deployment
        }

    def implement_exponential_backoff(self) -> dict:
        """å®æ–½æŒ‡æ•°é€€é¿"""

        # æ›´æ–°é…ç½®
        config = {
            "retry": {
                "max_attempts": 5,
                "initial_delay": 1000,  # 1ç§’
                "max_delay": 60000,     # 60ç§’
                "exponential_base": 2   # æŒ‡æ•°å¢é•¿
            }
        }

        # æ›´æ–°æœåŠ¡é…ç½®ï¼ˆç¤ºä¾‹ï¼‰
        # å®é™…å®ç°ä¸­ï¼Œå¯èƒ½éœ€è¦æ›´æ–°é…ç½®ä¸­å¿ƒæˆ–ç¯å¢ƒå˜é‡

        return {
            "action": "implement_exponential_backoff",
            "config": config
        }

    def _init_kubernetes(self):
        """åˆå§‹åŒ– Kubernetes å®¢æˆ·ç«¯"""
        from kubernetes import client, config

        try:
            config.load_incluster_config()
        except:
            config.load_kube_config()

        return client.AppsV1Api()

# ä½¿ç”¨ç¤ºä¾‹
executor = AutomationExecutor()

execution = executor.execute(decision)

print(f"æ‰§è¡ŒçŠ¶æ€: {execution['status']}")
print(f"æ‰§è¡Œæ—¶é•¿: {execution['duration']:.2f}ç§’")

for log in execution['execution_log']:
    print(f"  [{log['step']}] {log['message']}")
```

---

### é˜¶æ®µ 5: éªŒè¯ (Verify)

#### å¥åº·éªŒè¯å™¨

```python
class HealthVerifier:
    """å¥åº·éªŒè¯å™¨"""

    def __init__(self):
        self.verification_checks = {
            "error_rate": self._verify_error_rate,
            "latency": self._verify_latency,
            "resource_usage": self._verify_resource_usage,
            "service_health": self._verify_service_health,
        }

    def verify(self, original_event: dict, execution: dict) -> dict:
        """éªŒè¯ä¿®å¤æ˜¯å¦æˆåŠŸ"""

        if execution["status"] != "success":
            return {
                "verification_status": "failed",
                "reason": "Execution failed"
            }

        verification_results = {}

        # æ‰§è¡Œæ‰€æœ‰éªŒè¯æ£€æŸ¥
        for check_name, check_func in self.verification_checks.items():
            try:
                result = check_func(original_event)
                verification_results[check_name] = result
            except Exception as e:
                verification_results[check_name] = {
                    "status": "error",
                    "error": str(e)
                }

        # ç»¼åˆåˆ¤æ–­
        all_passed = all(
            r.get("status") == "passed"
            for r in verification_results.values()
        )

        return {
            "verification_status": "passed" if all_passed else "failed",
            "checks": verification_results,
            "timestamp": time.time()
        }

    def _verify_error_rate(self, event: dict) -> dict:
        """éªŒè¯é”™è¯¯ç‡æ˜¯å¦æ¢å¤æ­£å¸¸"""

        original_error_rate = event.get("metrics", {}).get("error_rate", 0)
        threshold = 0.05  # 5%

        # è·å–å½“å‰é”™è¯¯ç‡ï¼ˆå®é™…å®ç°ä¸­åº”è¯¥æŸ¥è¯¢ç›‘æ§ç³»ç»Ÿï¼‰
        current_error_rate = self._get_current_error_rate()

        passed = current_error_rate < threshold

        return {
            "status": "passed" if passed else "failed",
            "metric": "error_rate",
            "original": original_error_rate,
            "current": current_error_rate,
            "threshold": threshold,
            "improvement": original_error_rate - current_error_rate
        }

    def _verify_latency(self, event: dict) -> dict:
        """éªŒè¯å»¶è¿Ÿæ˜¯å¦æ¢å¤æ­£å¸¸"""

        original_latency = event.get("metrics", {}).get("latency_p95", 0)
        threshold = 1000  # 1000ms

        # è·å–å½“å‰å»¶è¿Ÿ
        current_latency = self._get_current_latency()

        passed = current_latency < threshold

        return {
            "status": "passed" if passed else "failed",
            "metric": "latency_p95",
            "original": original_latency,
            "current": current_latency,
            "threshold": threshold,
            "improvement": original_latency - current_latency
        }

    def _verify_resource_usage(self, event: dict) -> dict:
        """éªŒè¯èµ„æºä½¿ç”¨æ˜¯å¦æ­£å¸¸"""

        # è·å–å½“å‰èµ„æºä½¿ç”¨
        current_cpu = self._get_current_cpu_usage()
        current_memory = self._get_current_memory_usage()

        cpu_passed = current_cpu < 90
        memory_passed = current_memory < 85

        return {
            "status": "passed" if cpu_passed and memory_passed else "failed",
            "cpu": {
                "current": current_cpu,
                "status": "passed" if cpu_passed else "failed"
            },
            "memory": {
                "current": current_memory,
                "status": "passed" if memory_passed else "failed"
            }
        }

    def _verify_service_health(self, event: dict) -> dict:
        """éªŒè¯æœåŠ¡å¥åº·çŠ¶æ€"""

        service = event.get("service", "unknown")

        # æ‰§è¡Œå¥åº·æ£€æŸ¥
        health_check_passed = self._perform_health_check(service)

        return {
            "status": "passed" if health_check_passed else "failed",
            "service": service,
            "health_check": health_check_passed
        }

    def _get_current_error_rate(self) -> float:
        """è·å–å½“å‰é”™è¯¯ç‡ï¼ˆæ¨¡æ‹Ÿï¼‰"""
        # å®é™…å®ç°ä¸­ï¼Œåº”è¯¥æŸ¥è¯¢ Prometheus æˆ–å…¶ä»–ç›‘æ§ç³»ç»Ÿ
        return 0.02

    def _get_current_latency(self) -> float:
        """è·å–å½“å‰å»¶è¿Ÿï¼ˆæ¨¡æ‹Ÿï¼‰"""
        # å®é™…å®ç°ä¸­ï¼Œåº”è¯¥æŸ¥è¯¢ Prometheus æˆ–å…¶ä»–ç›‘æ§ç³»ç»Ÿ
        return 450.0

    def _get_current_cpu_usage(self) -> float:
        """è·å–å½“å‰ CPU ä½¿ç”¨ç‡ï¼ˆæ¨¡æ‹Ÿï¼‰"""
        return 65.0

    def _get_current_memory_usage(self) -> float:
        """è·å–å½“å‰å†…å­˜ä½¿ç”¨ç‡ï¼ˆæ¨¡æ‹Ÿï¼‰"""
        return 72.0

    def _perform_health_check(self, service: str) -> bool:
        """æ‰§è¡Œå¥åº·æ£€æŸ¥"""
        # å®é™…å®ç°ä¸­ï¼Œåº”è¯¥è°ƒç”¨æœåŠ¡çš„å¥åº·æ£€æŸ¥ç«¯ç‚¹
        return True

# ä½¿ç”¨ç¤ºä¾‹
verifier = HealthVerifier()

verification = verifier.verify(event, execution)

print(f"éªŒè¯çŠ¶æ€: {verification['verification_status']}")

for check_name, result in verification['checks'].items():
    print(f"  {check_name}: {result['status']}")
```

---

## ç¬¬ä¸‰éƒ¨åˆ†ï¼šå®Œæ•´çš„è‡ªæ„ˆåˆç³»ç»Ÿ

### ç³»ç»Ÿæ¶æ„

```python
class SelfHealingSystem:
    """å®Œæ•´çš„è‡ªæ„ˆåˆç³»ç»Ÿ"""

    def __init__(self):
        # äº”ä¸ªé˜¶æ®µ
        self.detector = AnomalyDetector()
        self.classifier = EventClassifier()
        self.decider = AIDecisionEngine(api_key=os.getenv("OPENAI_API_KEY"))
        self.executor = AutomationExecutor()
        self.verifier = HealthVerifier()

        # äº‹ä»¶å­˜å‚¨
        self.events_db = EventDatabase()

        # å‘Šè­¦ç³»ç»Ÿ
        self.alerting = AlertingSystem()

    def run(self):
        """è¿è¡Œè‡ªæ„ˆåˆç³»ç»Ÿï¼ˆæŒç»­ç›‘æ§ï¼‰"""

        logger.info("self_healing_system_started")

        while True:
            try:
                # è·å–æœ€æ–°æŒ‡æ ‡
                metrics = self._collect_metrics()

                # æ„å»ºäº‹ä»¶
                event = {
                    "service": "ai-chat-service",
                    "metrics": metrics,
                    "timestamp": time.time()
                }

                # å¤„ç†äº‹ä»¶
                result = self.handle_event(event)

                # è®°å½•ç»“æœ
                self.events_db.save(event, result)

                # å¦‚æœéœ€è¦äººå·¥ä»‹å…¥ï¼Œå‘é€å‘Šè­¦
                if result.get("action") == "human_intervention":
                    self.alerting.send_alert(event, result)

                # ç­‰å¾…ä¸‹ä¸€æ¬¡æ£€æŸ¥
                time.sleep(60)  # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡

            except Exception as e:
                logger.error("self_healing_loop_error", error=str(e))
                time.sleep(60)

    def handle_event(self, event: dict) -> dict:
        """å¤„ç†å•ä¸ªäº‹ä»¶"""

        logger.info("handling_event", event_id=event.get("event_id"))

        # é˜¶æ®µ 1: æ£€æµ‹
        detection = self.detector.detect(event)

        if not detection["is_anomaly"]:
            return {"action": "none", "reason": "No anomaly detected"}

        logger.warning(
            "anomaly_detected",
            anomalies=len(detection["anomalies"])
        )

        # é˜¶æ®µ 2: åˆ†ç±»
        classification = self.classifier.classify(event, detection)

        logger.info(
            "event_classified",
            type=classification["event_type"],
            severity=classification["severity"]
        )

        # é˜¶æ®µ 3: å†³ç­–
        decision = self.decider.decide(event, classification)

        logger.info(
            "decision_made",
            strategy=decision["strategy"],
            confidence=decision["confidence"]
        )

        # ç½®ä¿¡åº¦æ£€æŸ¥
        if decision["confidence"] < 0.8:
            logger.warning(
                "low_confidence",
                confidence=decision["confidence"],
                action="human_intervention_required"
            )
            return {
                "action": "human_intervention",
                "reason": "Low confidence",
                "decision": decision
            }

        # å®‰å…¨æ£€æŸ¥
        if not decision["safety_check"]["can_proceed"]:
            logger.warning(
                "safety_check_failed",
                status=decision["safety_check"]["overall_status"]
            )
            return {
                "action": "human_intervention",
                "reason": "Safety check failed",
                "decision": decision
            }

        # é˜¶æ®µ 4: æ‰§è¡Œ
        execution = self.executor.execute(decision)

        logger.info(
            "execution_completed",
            status=execution["status"],
            duration=execution.get("duration", 0)
        )

        # é˜¶æ®µ 5: éªŒè¯
        verification = self.verifier.verify(event, execution)

        logger.info(
            "verification_completed",
            status=verification["verification_status"]
        )

        # å¦‚æœéªŒè¯å¤±è´¥ï¼Œè®°å½•å¹¶å‘Šè­¦
        if verification["verification_status"] != "passed":
            logger.critical(
                "verification_failed",
                checks=verification["checks"]
            )
            self.alerting.send_alert(event, {
                "action": "auto_remediation_failed",
                "verification": verification
            })

        return {
            "action": "auto_remediated",
            "detection": detection,
            "classification": classification,
            "decision": decision,
            "execution": execution,
            "verification": verification
        }

    def _collect_metrics(self) -> dict:
        """æ”¶é›†æŒ‡æ ‡ï¼ˆå®é™…å®ç°ä¸­åº”ä» Prometheus ç­‰ç³»ç»Ÿè·å–ï¼‰"""
        # æ¨¡æ‹Ÿæ•°æ®
        return {
            "error_rate": 0.08,
            "latency_p95": 1200,
            "cpu_usage": 88,
            "memory_usage": 78,
        }

# å¯åŠ¨è‡ªæ„ˆåˆç³»ç»Ÿ
if __name__ == "__main__":
    system = SelfHealingSystem()
    system.run()
```

---

## ğŸ“Š çŸ¥è¯†æ£€æŸ¥

### è‡ªæˆ‘è¯„ä¼°é—®é¢˜

1. **è‡ªåŠ¨åŒ–äº‹ä»¶å“åº”çš„äº”ä¸ªé˜¶æ®µæ˜¯ä»€ä¹ˆï¼Ÿ**

2. **å¦‚ä½•ç¡®å®šäº‹ä»¶çš„ä¸¥é‡ç¨‹åº¦å’Œä¼˜å…ˆçº§ï¼Ÿ**

3. **AI å†³ç­–å¼•æ“å¦‚ä½•é€‰æ‹©æœ€ä½³ä¿®å¤ç­–ç•¥ï¼Ÿ**

4. **ä¸ºä»€ä¹ˆéœ€è¦å®‰å…¨æ£€æŸ¥ï¼Ÿå“ªäº›æ“ä½œéœ€è¦ç‰¹åˆ«è°¨æ…ï¼Ÿ**

5. **å¦‚ä½•éªŒè¯è‡ªåŠ¨åŒ–ä¿®å¤æ˜¯å¦æˆåŠŸï¼Ÿ**

6. **åœ¨ä»€ä¹ˆæƒ…å†µä¸‹åº”è¯¥é€‰æ‹©äººå·¥ä»‹å…¥è€Œä¸æ˜¯è‡ªåŠ¨åŒ–ä¿®å¤ï¼Ÿ**

---

## ğŸ“š å»¶ä¼¸é˜…è¯»

### èµ„æº

1. [Google SRE Book - Incident Management](https://sre.google/sre-book/incident-management/)
2. [AWS Auto Scaling](https://aws.amazon.com/autoscaling/)
3. [Kubernetes Self-Healing](https://kubernetes.io/docs/concepts/workloads/controllers/deployment/)

### æ¡ˆä¾‹ç ”ç©¶

1. **Netflix Chaos Engineering**: æ··æ²Œå·¥ç¨‹å®è·µ
2. **Google SRE**: ç«™ç‚¹å¯é æ€§å·¥ç¨‹
3. **Resolve å¹³å°**: AI é©±åŠ¨çš„è¿ç»´è‡ªåŠ¨åŒ–

---

**Week 9 ç»“è¯­**: é€šè¿‡æœ¬å‘¨çš„å­¦ä¹ ï¼Œä½ å·²ç»æŒæ¡äº†æ„å»ºè‡ªæ„ˆåˆç³»ç»Ÿçš„å®Œæ•´æŠ€æœ¯æ ˆã€‚ä¸‹ä¸€å‘¨ï¼Œæˆ‘ä»¬å°†æ¢è®¨ AI è½¯ä»¶å·¥ç¨‹çš„æœªæ¥ï¼Œå±•æœ›å¼€å‘è€…è§’è‰²çš„æ¼”å˜å’Œæœªæ¥åå¹´çš„å‘å±•è¶‹åŠ¿ã€‚
